/// Sensor Fusion Component - IMPORTS multiple sensor streams, EXPORTS fused environment model
package adas:sensor-fusion@0.1.0;

world sensor-fusion-component {
    /// Import camera data
    import camera-data: interface {
        record camera-frame {
            width: u32,
            height: u32,
            data: list<u8>,
            format: pixel-format,
            timestamp: u64,
            exposure-time: f32,
            gain: f32,
        }

        enum pixel-format {
            rgb8,
            rgba8,
            bgr8,
            bgra8,
            yuv420,
            gray8,
            gray16,
        }

        resource camera-stream {
            get-frame: func() -> result<camera-frame, string>;
            is-available: func() -> bool;
        }
        
        create-stream: func() -> camera-stream;
    }

    /// Import radar data
    import radar-data: interface {
        record position3d {
            x: f64,
            y: f64,
            z: f64,
        }

        record velocity3d {
            vx: f64,
            vy: f64,
            vz: f64,
            speed: f64,
        }

        record radar-scan {
            targets: list<radar-target>,
            timestamp: u64,
            scan-id: u32,
        }

        record radar-target {
            position: position3d,
            velocity: velocity3d,
            range: f64,
            azimuth: f64,
            elevation: f64,
            rcs: f64,
            signal-strength: f64,
            confidence: f32,
        }

        resource radar-stream {
            get-scan: func() -> result<radar-scan, string>;
            is-available: func() -> bool;
        }
        
        create-stream: func() -> radar-stream;
    }

    /// Import detection data from AI
    import detection-data: interface {
        record position3d {
            x: f64,
            y: f64,
            z: f64,
        }

        record velocity3d {
            vx: f64,
            vy: f64,
            vz: f64,
            speed: f64,
        }

        record detected-object {
            object-id: u32,
            object-type: object-type,
            position: position3d,
            velocity: velocity3d,
            confidence: f32,
        }

        record detection-results {
            objects: list<detected-object>,
            timestamp: u64,
            frame-id: string,
            confidence-threshold: f32,
        }

        enum object-type {
            unknown,
            vehicle,
            pedestrian,
            cyclist,
            motorcycle,
            truck,
            bus,
            traffic-sign,
            traffic-light,
            construction-zone,
            road-debris,
        }

        resource detection-stream {
            get-detections: func() -> result<detection-results, string>;
            is-available: func() -> bool;
        }
        
        create-stream: func() -> detection-stream;
    }
    
    /// Export fused environment model
    export fusion-data: interface {
        record position3d {
            x: f64,
            y: f64,
            z: f64,
        }

        record velocity3d {
            vx: f64,
            vy: f64,
            vz: f64,
            speed: f64,
        }

        record environment-model {
            objects: list<fused-object>,
            timestamp: u64,
            fusion-quality: f32,
            coverage-area: coverage-area,
        }

        record fused-object {
            object-id: u32,
            object-type: object-type,
            position: position3d,
            velocity: velocity3d,
            confidence: f32,
            source-sensors: list<sensor-type>,
            tracking-state: tracking-state,
        }

        record coverage-area {
            forward-range: f64,
            lateral-range: f64,
            angular-coverage: f32,
        }

        enum object-type {
            unknown,
            vehicle,
            pedestrian,
            cyclist,
            motorcycle,
            truck,
            bus,
            traffic-sign,
            traffic-light,
            construction-zone,
            road-debris,
        }

        enum sensor-type {
            camera,
            radar,
            lidar,
            ultrasonic,
        }

        enum tracking-state {
            new,
            tracked,
            lost,
            deleted,
        }

        resource fusion-stream {
            get-environment: func() -> result<environment-model, string>;
            is-available: func() -> bool;
            get-object-count: func() -> u32;
        }
        
        create-stream: func() -> fusion-stream;
    }
    
    /// Export fusion control interface
    export fusion-control: interface {
        record fusion-config {
            fusion-algorithm: fusion-algorithm,
            confidence-threshold: f32,
            temporal-window: f32,
            spatial-tolerance: f64,
            tracking-enabled: bool,
            calibration-mode: calibration-mode,
        }

        enum fusion-algorithm {
            simple-average,
            weighted-average,
            kalman-filter,
            particle-filter,
            deep-fusion,
        }

        enum calibration-mode {
            auto,
            manual,
            factory,
        }

        enum fusion-status {
            offline,
            initializing,
            calibrating,
            fusing,
            error,
            maintenance,
        }

        record performance-metrics {
            fusion-accuracy: f32,
            processing-latency: f32,
            data-association-rate: f32,
            false-positive-rate: f32,
            false-negative-rate: f32,
            sensor-availability: list<sensor-status>,
        }

        record sensor-status {
            sensor-type: sensor-type,
            availability: f32,
            data-quality: f32,
        }

        enum sensor-type {
            camera,
            radar,
            lidar,
            ultrasonic,
        }

        record diagnostic-result {
            calibration-status: test-result,
            data-association: test-result,
            temporal-consistency: test-result,
            spatial-accuracy: test-result,
            sensor-synchronization: test-result,
            overall-score: f32,
        }

        enum test-result {
            passed,
            failed,
            warning,
            not-tested,
        }

        /// Initialize fusion system
        initialize: func(config: fusion-config) -> result<_, string>;
        
        /// Start sensor fusion
        start-fusion: func() -> result<_, string>;
        
        /// Stop sensor fusion
        stop-fusion: func() -> result<_, string>;
        
        /// Update configuration
        update-config: func(config: fusion-config) -> result<_, string>;
        
        /// Get system status
        get-status: func() -> fusion-status;
        
        /// Get performance metrics
        get-performance: func() -> performance-metrics;
        
        /// Run diagnostics
        run-diagnostic: func() -> result<diagnostic-result, string>;
    }
}