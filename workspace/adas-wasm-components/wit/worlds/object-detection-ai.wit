/// Object Detection AI Component - IMPORTS camera data, IMPORTS wasi-nn, EXPORTS detection results
package adas:object-detection-ai@0.1.0;

world object-detection-component {
    import wasi:cli/environment@0.2.3;
    import wasi:cli/exit@0.2.3;
    import wasi:io/streams@0.2.3;
    import wasi:cli/stdout@0.2.3;
    import wasi:cli/stderr@0.2.3;
    import wasi:clocks/monotonic-clock@0.2.3;
    import wasi:clocks/wall-clock@0.2.3;

    /// Import camera data from camera components
    import adas:sensor-data/camera-data@0.1.0;
    
    /// Import WASI-NN for neural network inference
    import wasi:nn/graph@0.2.0;
    import wasi:nn/tensor@0.2.0;
    import wasi:nn/inference@0.2.0;
    
    /// Export detection results for other components to consume
    export adas:sensor-data/detection-data@0.1.0;
    
    /// AI control interface for configuration and management
    export ai-control: interface {
        /// Initialize AI system with model and configuration
        initialize: func(config: ai-config) -> result<_, string>;
        
        /// Load neural network model
        load-model: func(model-path: string, model-type: model-type) -> result<_, string>;
        
        /// Start object detection processing
        start-detection: func() -> result<_, string>;
        
        /// Stop object detection processing
        stop-detection: func() -> result<_, string>;
        
        /// Update AI configuration
        update-config: func(config: ai-config) -> result<_, string>;
        
        /// Get AI system status
        get-status: func() -> ai-status;
        
        /// Get performance metrics
        get-performance: func() -> performance-metrics;
        
        /// Run AI system diagnostics
        run-diagnostic: func() -> result<diagnostic-result, string>;
    }

    /// AI system configuration
    record ai-config {
        model-path: string,
        confidence-threshold: f32,
        nms-threshold: f32,
        input-resolution: resolution,
        batch-size: u32,
        inference-device: inference-device,
        performance-mode: performance-mode,
    }

    enum model-type {
        yolo-v5,
        yolo-v8,
        ssd-mobilenet,
        faster-rcnn,
        efficientdet,
        custom,
    }

    record resolution {
        width: u32,
        height: u32,
    }

    enum inference-device {
        cpu,
        gpu,
        npu,
        auto,
    }

    enum performance-mode {
        accuracy,
        speed,
        balanced,
        power-efficient,
    }

    enum ai-status {
        offline,
        initializing,
        loading-model,
        ready,
        processing,
        error,
        maintenance,
    }

    record performance-metrics {
        inference-time-ms: f32,
        fps: f32,
        cpu-usage-percent: f32,
        memory-usage-mb: u32,
        gpu-usage-percent: f32,
        model-accuracy: f32,
        throughput-hz: f32,
    }

    record diagnostic-result {
        model-integrity: test-result,
        inference-engine: test-result,
        memory-test: test-result,
        performance-test: test-result,
        accuracy-test: test-result,
        overall-score: f32,
    }

    enum test-result {
        passed,
        failed,
        warning,
        not-tested,
    }
}