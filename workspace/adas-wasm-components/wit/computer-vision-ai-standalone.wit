package adas:computer-vision@0.1.0;

/// Advanced computer vision AI for scene understanding
interface computer-vision {
    /// WASI-NN compatible types for neural network inference
    /// (Local definitions until WASI-NN runtime support is available)
    type nn-tensor-dimensions = list<u32>;
    
    enum nn-tensor-type {
        fp16, fp32, fp64, bf16, uint8, int32, int64
    }
    
    type nn-tensor-data = list<u8>;
    
    record nn-tensor {
        dimensions: nn-tensor-dimensions,
        tensor-type: nn-tensor-type,
        data: nn-tensor-data,
    }
    
    enum nn-graph-encoding {
        openvino, onnx, tensorflow, pytorch,
        tensorflowlite, ggml, autodetect
    }
    
    enum nn-execution-target {
        cpu, gpu, tpu
    }
    /// Scene understanding result
    record scene-analysis {
        timestamp: u64,
        frame-id: u32,
        road-segmentation: road-segmentation,
        weather-conditions: weather-conditions,
        lighting-conditions: lighting-conditions,
        scene-complexity: scene-complexity,
        drivable-area: drivable-area,
    }

    record road-segmentation {
        road-pixels: list<pixel-region>,
        lane-pixels: list<pixel-region>,
        sidewalk-pixels: list<pixel-region>,
        building-pixels: list<pixel-region>,
        vegetation-pixels: list<pixel-region>,
        sky-pixels: list<pixel-region>,
        confidence-map: list<f32>,
    }

    record pixel-region {
        start-x: u32,
        start-y: u32,
        width: u32,
        height: u32,
        classification: pixel-class,
        confidence: f32,
    }

    enum pixel-class {
        road,
        lane-marking,
        sidewalk,
        building,
        vegetation,
        sky,
        vehicle,
        person,
        traffic-sign,
        traffic-light,
        unknown,
    }

    record weather-conditions {
        condition: weather-type,
        visibility: visibility-level,
        precipitation-intensity: f32,
        confidence: f32,
    }

    enum weather-type {
        clear,
        cloudy,
        rain,
        snow,
        fog,
        hail,
        unknown,
    }

    enum visibility-level {
        excellent,
        good,
        moderate,
        poor,
        very-poor,
    }

    record lighting-conditions {
        light-level: light-level,
        light-direction: light-direction,
        shadows-present: bool,
        glare-detected: bool,
        artificial-lighting: bool,
    }

    enum light-level {
        bright-daylight,
        daylight,
        dusk,
        dawn,
        night,
        artificial,
    }

    enum light-direction {
        front,
        back,
        left,
        right,
        overhead,
        multiple,
    }

    record scene-complexity {
        object-density: density-level,
        motion-complexity: motion-level,
        occlusion-level: occlusion-level,
        overall-complexity: complexity-level,
    }

    enum density-level {
        sparse,
        moderate,
        dense,
        very-dense,
    }

    enum motion-level {
        stationary,
        low-motion,
        moderate-motion,
        high-motion,
    }

    enum occlusion-level {
        none,
        minimal,
        moderate,
        significant,
    }

    enum complexity-level {
        simple,
        moderate,
        complex,
        very-complex,
    }

    record drivable-area {
        free-space: list<polygon>,
        obstacles: list<obstacle-region>,
        confidence: f32,
        safe-zones: list<polygon>,
        risk-zones: list<polygon>,
    }

    record polygon {
        vertices: list<point2d>,
        area: f32,
    }

    record point2d {
        x: f32,
        y: f32,
    }

    record obstacle-region {
        polygon: polygon,
        obstacle-type: obstacle-type,
        confidence: f32,
        height-estimate: option<f32>,
    }

    enum obstacle-type {
        vehicle,
        pedestrian,
        stationary-object,
        construction,
        debris,
        unknown,
    }

    /// Input frame for processing
    record vision-frame {
        width: u32,
        height: u32,
        pixel-format: pixel-format,
        data: list<u8>,
        timestamp: u64,
        camera-params: camera-parameters,
    }

    enum pixel-format {
        rgb888,
        bgr888,
        yuv420,
        nv12,
    }

    record camera-parameters {
        focal-length: f32,
        principal-point: point2d,
        distortion: list<f32>,
        exposure: f32,
        gain: f32,
    }

    /// Vision system configuration
    record vision-config {
        segmentation-enabled: bool,
        weather-detection-enabled: bool,
        lighting-analysis-enabled: bool,
        free-space-detection-enabled: bool,
        processing-resolution: resolution,
        ai-model-precision: precision-level,
    }

    enum resolution {
        low-resolution,
        medium-resolution,
        high-resolution,
        ultra-resolution,
    }

    enum precision-level {
        fast,
        balanced,
        accurate,
        ultra-accurate,
    }

    enum vision-status {
        offline,
        initializing,
        active,
        error,
        model-loading,
        degraded,
    }

    /// Initialize computer vision system
    initialize: func(config: vision-config) -> result<_, string>;

    /// Start vision processing
    start-processing: func() -> result<_, string>;

    /// Stop vision processing
    stop-processing: func() -> result<_, string>;

    /// Analyze scene from input frame
    analyze-scene: func(frame: vision-frame) -> result<scene-analysis, string>;

    /// Get drivable area analysis
    get-drivable-area: func(frame: vision-frame) -> result<drivable-area, string>;

    /// Detect weather conditions
    detect-weather: func(frame: vision-frame) -> result<weather-conditions, string>;

    /// Analyze lighting conditions
    analyze-lighting: func(frame: vision-frame) -> result<lighting-conditions, string>;

    /// Get vision system status
    get-status: func() -> vision-status;

    /// Update configuration
    update-config: func(config: vision-config) -> result<_, string>;

    /// Run system diagnostic
    run-diagnostic: func() -> result<diagnostic-result, string>;

    record diagnostic-result {
        model-performance: f32,
        processing-speed: f32,
        memory-usage: u32,
        gpu-utilization: option<f32>,
        segmentation-accuracy: f32,
        weather-detection-accuracy: f32,
    }

}

world computer-vision-component {
    /// WASI-NN support prepared for future integration
    /// Currently using local type definitions
    export computer-vision;
}