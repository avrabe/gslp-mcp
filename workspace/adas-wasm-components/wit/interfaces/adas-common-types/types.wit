package adas:common-types;

/// Shared automotive data types for ADAS components
/// Ensures consistency across all ECUs and AI processing modules
interface types {
    /// Common timestamp type (microseconds since epoch)
    type timestamp = u64;

    /// Standard 3D position in automotive coordinate system
    /// Uses f64 for high precision GPS/mapping coordinates
    record position3d {
        x: f64,  // Forward (meters)
        y: f64,  // Left (meters) 
        z: f64,  // Up (meters)
        coordinate-frame: coordinate-frame,
    }

    /// 3D velocity vector
    record velocity3d {
        vx: f64, // Forward velocity (m/s)
        vy: f64, // Lateral velocity (m/s)
        vz: f64, // Vertical velocity (m/s)
        speed: f64, // Magnitude for convenience (m/s)
    }

    /// 3D acceleration vector
    record acceleration3d {
        ax: f32, // Forward acceleration (m/s²)
        ay: f32, // Lateral acceleration (m/s²)
        az: f32, // Vertical acceleration (m/s²)
        magnitude: f32, // Magnitude for convenience (m/s²)
    }

    /// Physical dimensions for bounding boxes
    record dimensions3d {
        length: f32, // Forward dimension (meters)
        width: f32,  // Lateral dimension (meters)
        height: f32, // Vertical dimension (meters)
    }

    /// Quaternion for 3D orientation (x,y,z,w order)
    record quaternion {
        x: f32,
        y: f32,
        z: f32,
        w: f32,
    }

    /// Euler angles (radians)
    record orientation3d {
        yaw: f32,   // Rotation around Z-axis (radians)
        pitch: f32, // Rotation around Y-axis (radians)
        roll: f32,  // Rotation around X-axis (radians)
    }

    /// 3D bounding box with center and orientation
    record bounding-box3d {
        center: position3d,
        dimensions: dimensions3d,
        orientation: quaternion,
    }

    /// 2D position for image/screen coordinates
    record position2d {
        x: f32,
        y: f32,
    }

    /// 2D bounding box for image detection
    record bounding-box2d {
        x: f32,      // Top-left X
        y: f32,      // Top-left Y
        width: f32,  // Width in pixels
        height: f32, // Height in pixels
    }

    /// Standard coordinate frame reference
    enum coordinate-frame {
        local,        // Vehicle body frame
        utm,          // Universal Transverse Mercator
        wgs84,        // World Geodetic System 1984
        map,          // Local map frame
        camera,       // Camera frame
        lidar,        // LiDAR frame
    }

    /// Standardized object types for automotive domain
    enum object-type {
        unknown,
        // Vehicles
        vehicle,
        car,                    // Alias for vehicle
        truck,
        bus,
        motorcycle,
        bicycle,
        emergency-vehicle,
        construction-vehicle,
        // Vulnerable road users
        pedestrian,
        cyclist,
        // Infrastructure  
        traffic-sign,
        traffic-light,
        road-marking,
        construction-cone,
        barrier,
        pole,
        // Hazards
        debris,
        animal,
        stationary-object,
    }

    /// Health status for system monitoring
    enum health-status {
        ok,
        warning,
        error,
        critical,
        offline,
        degraded,
    }

    /// Test result enumeration
    enum test-result {
        passed,
        failed,
        error,
        timeout,
        not-run,
    }

    /// Sensor data quality metrics
    record data-quality {
        confidence: f32,        // 0.0 to 1.0
        signal-strength: f32,   // Sensor-specific units
        noise-level: f32,       // Signal-to-noise ratio
        timestamp-accuracy: f32, // Timing precision (ms)
        calibration-valid: bool,
    }

    /// Vehicle kinematic state
    record vehicle-kinematics {
        position: position3d,
        velocity: velocity3d,
        acceleration: acceleration3d,
        orientation: orientation3d,
        angular-velocity: velocity3d, // rad/s around each axis (vx=roll, vy=pitch, vz=yaw)
        timestamp: timestamp,
    }

    /// Automotive safety integrity levels (ISO 26262)
    enum asil-level {
        qm,    // Quality Managed
        asil-a,
        asil-b,
        asil-c,
        asil-d,
    }

    /// Real-time constraints
    record timing-constraints {
        max-latency-ms: u32,
        max-jitter-ms: u32,
        update-frequency-hz: f32,
        deadline-type: deadline-type,
    }

    enum deadline-type {
        soft,
        firm,
        hard,
    }

    /// Performance metrics common across components
    record performance-metrics {
        latency-avg-ms: f32,
        latency-max-ms: f32,
        cpu-utilization: f32,    // 0.0 to 1.0
        memory-usage-mb: u32,
        throughput-hz: f32,
        error-rate: f32,         // 0.0 to 1.0
    }

    /// Sensor capabilities and limits
    record sensor-specification {
        max-range-m: f32,
        min-range-m: f32,
        horizontal-fov-deg: f32,
        vertical-fov-deg: f32,
        resolution: sensor-resolution,
        update-rate-hz: f32,
        accuracy: f32,
    }

    record sensor-resolution {
        horizontal: u32,
        vertical: u32,
        depth-bits: u32,
    }

    /// Standard automotive CAN message
    record can-message {
        message-id: u32,
        extended-id: bool,
        data: list<u8>,
        data-length: u8,
        timestamp: timestamp,
        bus-id: u32,
        priority: u8,
        error-flags: u32,
    }

    /// Weather conditions affecting sensors
    enum weather-condition {
        clear,
        light-rain,
        heavy-rain,
        snow,
        fog,
        sandstorm,
        hail,
    }

    /// Time of day affecting lighting
    enum lighting-condition {
        bright-daylight,
        daylight,
        dawn,
        dusk,
        night,
        artificial-lighting,
        tunnel,
    }

    /// Traffic density levels
    enum traffic-density {
        empty,
        light,
        moderate,
        heavy,
        congested,
    }
}

/// Sensor fusion specific types
interface sensor-fusion {
    use types.{position3d, velocity3d, acceleration3d, timestamp, data-quality};

    /// Multi-sensor fused object
    record fused-object {
        object-id: u32,
        position: position3d,
        velocity: velocity3d,
        acceleration: acceleration3d,
        covariance-matrix: list<f64>, // State uncertainty
        sensor-sources: list<sensor-source>,
        track-age: u32,
        confidence: f32,
        timestamp: timestamp,
    }

    enum sensor-source {
        camera-front,
        camera-surround,
        radar-front,
        radar-corner,
        lidar,
        ultrasonic,
        v2x,
        map-data,
    }

    /// Kalman filter state
    record kalman-state {
        state-vector: list<f64>,
        covariance-matrix: list<f64>,
        process-noise: list<f64>,
        measurement-noise: list<f64>,
        timestamp: timestamp,
    }
}